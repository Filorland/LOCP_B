{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5197a750",
    "execution_start": 1653930466814,
    "execution_millis": 4900,
    "cell_id": "f32e6662-11b7-4c43-b228-34ea085856d8",
    "owner_user_id": "d8aa7146-c8e6-479e-9e49-136a058e4f85",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 495
   },
   "source": "import wandb\nfrom wandb.keras import WandbCallback\nimport numpy as np\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dropout, Input, Flatten, Dense, Concatenate\nfrom tensorflow.keras.losses import CategoricalCrossentropy, Huber, MeanSquaredError\nfrom tensorflow.keras.metrics import categorical_accuracy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\nfrom tf_agents.environments import py_environment\nfrom tf_agents.trajectories import trajectory\nfrom tf_agents.trajectories import time_step as ts\nfrom tf_agents.specs import array_spec, tensor_spec\n\nfrom spektral.layers import XENetDenseConv\nfrom spektral.utils.sparse import sp_matrix_to_sp_tensor\nfrom spektral.data import Graph\nfrom spektral.data.dataset import Dataset\nfrom spektral.data.loaders import BatchLoader",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "f701c8361d68485b9235144bcfb048ac",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d713b76e",
    "execution_start": 1653930471715,
    "execution_millis": 3748,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 486.875,
    "deepnote_output_heights": [
     null,
     21.1875,
     22.1875,
     21.1875,
     27.1875
    ]
   },
   "source": "# initialize wandb\n\nwandb.init(project=\"test-project\", \n           entity=\"locp\")",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfilippo_festa\u001b[0m (\u001b[33mlocp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.17"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/work/wandb/run-20220530_170752-1blglopm</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/locp/test-project/runs/1blglopm\" target=\"_blank\">golden-star-13</a></strong> to <a href=\"https://wandb.ai/locp/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/locp/test-project/runs/1blglopm?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7fb3763cbf50>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Parameters to be set:\n- number of train_episodes\n- size of replay_memory\n- update steps of main and target network\n- discount_factor\n- MIN_REPLAY_SIZE (minimum size of the replay_memory for which we do the training)\n- batch_size (size of the training dataset)",
   "metadata": {
    "tags": [],
    "cell_id": "00001-80747c27-ffb0-4baa-a231-56f8726bf183",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 229.734375
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Predefined Functions ",
   "metadata": {
    "tags": [],
    "cell_id": "00002-3e5cdd67-404f-467e-9eee-8ed4cf14dc4b",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Adjacency Matrix ",
   "metadata": {
    "tags": [],
    "cell_id": "00003-51941097-98ab-4011-8574-c8c86dc93719",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "63f6794e",
    "execution_start": 1653930475468,
    "execution_millis": 7,
    "cell_id": "00004-7136cfbb-0cd0-4475-bca5-c5d1bc6b0053",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 802.375
   },
   "source": "def Adj(D, L, sparse=False):\n    N = L**D\n\n    # create all nodes' coordinates\n    nodes = [x for x in np.ndindex(tuple(np.repeat(L,D)))]\n\n    # Pass from coordinate to node's index\n    # (h,...k,j,i) <=> index = h*L^(D-1) + ... + k*L^2 + j*L + i\n    mul = [L**i for i in reversed(range(D))]\n\n    # Creation of adjacency matrix \n    A_dense = []\n    # creation of a row for each node's coordinate \n    for node in nodes:       \n        temp_buffer = []\n        A_dense_row = [0]*N\n        # find the two nearest neighbours of the node along each dimension\n        for d in range(D):\n            temp=list(node)\n            temp[d]=((temp[d]+1)%L)\n            temp=np.inner(temp, mul)\n            temp_buffer.append(temp)    \n\n            temp=list(node)\n            temp[d]=((temp[d]-1)%L)\n            temp=np.inner(temp, mul)\n            temp_buffer.append(temp)\n      \n        temp_buffer=list(np.unique(np.array(temp_buffer), axis=0))   \n        for i in temp_buffer: A_dense_row[i]=1\n        A_dense.append(A_dense_row)\n    \n    # sparse=False => sparse adjacency matrix\n    # sparse=True => dense adjacency matrix\n    if sparse:\n        return sp_matrix_to_sp_tensor(np.array(A_dense))\n    else:\n        return np.array(A_dense)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Interaction Matrix ",
   "metadata": {
    "tags": [],
    "cell_id": "00005-3fc681ac-44d3-4633-bb60-962313c945b8",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3c2729e3",
    "execution_start": 1653930475480,
    "execution_millis": 2,
    "cell_id": "00006-5621d98c-bcb6-4ee2-8500-27b39da70153",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 657
   },
   "source": "def J_inter(denseAdj):\n    N = denseAdj.shape[0]\n    sparseAdj = sp_matrix_to_sp_tensor(denseAdj)\n\n    # sparse adjacency matrix as a numpy array\n    edge=sparseAdj.indices.numpy()\n\n    # ordered numpy sparse adjacency matrix\n    un_edge=np.array([np.sort(i) for i in edge]) \n\n    # creation of the interaction array: (i,j) and (j,i) have the same Jij\n    inter=[]\n    for i in range(len(un_edge)):\n        equal=True\n        for j in range(i):\n            if np.array_equal(un_edge[i],un_edge[j]):\n                inter.append(inter[j])\n                equal=False\n                break\n        if equal: \n            inter.append(np.random.normal(0, 1))\n    \n    # creation of dense interaction matrix\n    inter_matrix = np.zeros((N,N))\n    counter = 0\n    for i, j in edge:\n        inter_matrix[i,j] = inter[counter]\n        counter += 1\n    return [np.array(inter).reshape(sparseAdj.indices.shape[0],1), inter_matrix.reshape((N,N,1))]\n    \n    # index of the returned list:\n    # 0 => interaction array\n    # 1 => interaction matrix (zero padded)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Dataset",
   "metadata": {
    "tags": [],
    "cell_id": "00007-764c0350-ac33-4f21-8428-8a09dbf30b04",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5630b81b",
    "execution_start": 1653930475487,
    "execution_millis": 27,
    "cell_id": "00008-19d7cf39-e0df-48eb-a951-193cae75ebf8",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369
   },
   "source": "class MyDataset(Dataset):\n    def __init__(self, N_graph, X, Y, A, E, **kwargs):\n        self.X = X\n        self.Y = Y\n        self.N_graph = N_graph\n        self.A = A\n        self.E = E\n        super().__init__(**kwargs)\n\n    def read(self):\n        mydataset = []\n        for i in range(self.N_graph):\n            # list of Graph objects that will be used as input in the BatchLoader\n            mydataset.append(\n                    Graph(x=self.X[i], a=self.A[i], e=self.E[i], y=self.Y[i])      \n                    )\n        return mydataset",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Replay memory buffer",
   "metadata": {
    "tags": [],
    "cell_id": "00009-e8c623f1-4fe0-422e-925c-cd200f08d1ba",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8ae44cb4",
    "execution_start": 1653930475515,
    "execution_millis": 0,
    "cell_id": "00010-3b986364-9853-439a-8200-6020a274d22d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 405
   },
   "source": "# save n-step transitions (s_t; a_t; r_t,t+n; s_t+n) from the trajectory buffer\n\ndef get_replay_memory(trajectory_buffer, replay_memory):\n    n = len(trajectory_buffer)\n\n    states = np.array([transition[0] for transition in trajectory_buffer])\n    actions = np.array([transition[1] for transition in trajectory_buffer])\n    rewards = np.array([transition[2] for transition in trajectory_buffer])\n    done = np.array([transition[4] for transition in trajectory_buffer])\n    inter_matrix = trajectory_buffer[0][-1]\n    dense_AdjMat = trajectory_buffer[0][-2]\n\n    cum_reward = np.cumsum(rewards)\n\n    # creating the replay memory buffer from the trajectory one\n    # => (starting state, action performed, cumulative reward after n step from the starting one, state after n step from the starting one, episode ended, dense adjacency matrix of the episode, interaction matrix of the episode)\n    replay_memory.append([states[0], actions[0], cum_reward[n-1], states[n-1], done[n-1], dense_AdjMat, inter_matrix])\n\n    return replay_memory",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Environment ",
   "metadata": {
    "tags": [],
    "cell_id": "00011-df4a778e-1dab-41f2-85af-e2ecb3bf69a6",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "746d70c6",
    "execution_start": 1653930475516,
    "execution_millis": 4,
    "cell_id": "00012-7132212d-2d89-4da1-833c-f12717377c7b",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1881
   },
   "source": "class SG_env(py_environment.PyEnvironment):\n\n  def __init__(self, L, D):\n    # Initialize environment attributes\n    # - action_spec: action declaration (integer from 0 to N-1)\n    # - observation_spec: state of the system declaration\n    # - episode_ended: flag for the end of the episode (all spin down)\n    # - state: state of the system (1 and -1 array)\n    self.N = L**D\n    self._action_spec = array_spec.BoundedArraySpec(\n        shape=(), dtype=np.int32, minimum=0, maximum=self.N-1, name='action')\n    self._observation_spec = array_spec.BoundedArraySpec(\n        shape=(self.N,1), dtype=np.int32, minimum=-1, maximum=1, name='observation')\n    self.sp_AdjMat = Adj(D, L, sparse=True)\n    self.dense_AdjMat = Adj(D, L, sparse=False)\n    self.interaction = J_inter(self.dense_AdjMat)[0]   \n    self.inter_matrix = J_inter(self.dense_AdjMat)[1]\n    self._state = np.ones(shape=(self.N,1)).astype(\"int32\")\n    self._episode_ended = False\n\n  def get_state(self):\n    return self._state\n\n  def show_N(self):\n    return self.N  \n\n  def action_spec(self):\n    return self._action_spec\n\n  def observation_spec(self):\n    return self._observation_spec\n\n  def show_dense_AdjMat(self):\n    return self.dense_AdjMat\n\n  def show_sp_AdjMat(self):\n    return self.sp_AdjMat\n\n  def show_interaction(self):\n    return self.interaction\n\n  def show_inter_matrix(self):\n    return self.inter_matrix\n\n  # True => All spins = -1, False => otherwise\n  def __all_spins_down(self):\n    return np.all(self._state==-1)    \n\n  # Compute the reward of the chosen action \n  # reward = energy difference between consecutive states\n  # nns => nearest neighbours indexes\n  # nn_Js => nearest neighbours interactions' indexes\n  def computeReward(self, action):\n    nns = self.sp_AdjMat.indices[self.sp_AdjMat.indices[:,0]==action][:,1].numpy()\n    nn_Js = np.where(self.sp_AdjMat.indices[:,0]==action)[0]\n    nn_sum = 0\n    for i in range(len(nns)): nn_sum += self.interaction[nn_Js[i]]*self._state[nns[i],0]\n    reward = 2*nn_sum*self._state[action,0]\n    return reward[0]\n\n  # Compute the energy of the current state \n  def computeEnergy(self):\n    edge = self.sp_AdjMat.indices.numpy()\n    Nedge = len(edge)\n    energy = 0\n    for i in range(Nedge):\n        energy -= self.interaction[i][0]*self._state[edge[i][0]][0]*self._state[edge[i][1]][0]\n    return energy/2\n\n  # reset function: called when all spins are -1 => new episode\n  #                                              => all spins up (=1) and new interaction matrix (if needed)\n  def _reset(self):\n    self._state = np.ones(shape=(self.N,1)).astype(\"int32\")\n    #self.interaction = J_inter(self.dense_AdjMat)[0]    \n    #self.inter_matrix = J_inter(self.dense_AdjMat)[1]\n    self._episode_ended = False\n    return ts.restart(np.array(self._state, dtype=np.int32))\n\n  # step function: describe the process of applying the action selected by the agent\n  # ts.restart, ts.transition and ts.termination return a timestep \n  # containing step_type, reward, discount and observation\n  def _step(self, action):\n    if self._episode_ended:\n      return self.reset()\n\n    if self.__all_spins_down():\n      self._episode_ended = True\n    elif (action>=0 and action<=self.N-1) and (self._state[action,0]==1):\n      self._state[action,0]=-1\n      rew = self.computeReward(action)\n      \n      if self.__all_spins_down():\n          self._episode_ended = True\n          return ts.termination(np.array(self._state, dtype=np.int32), reward=rew)\n      else:\n          return ts.transition(np.array(self._state, dtype=np.int32), reward=rew)\n    \n    elif (action>=0 and action<=self.N-1) and (self._state[action,0]==-1):\n      raise ValueError('Each spin can be flipped only once!')\n    else:\n      raise ValueError('`action` should be 0 up to N-1 - Spin Flip!')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Agent",
   "metadata": {
    "tags": [],
    "cell_id": "00013-8ea1f231-3432-43fc-8b05-f004ea4ccc0f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "517364c3",
    "execution_start": 1653930475547,
    "execution_millis": 1,
    "cell_id": "00014-fbc62ac1-c83b-4a87-ae9e-b24405ce64ce",
    "owner_user_id": "55930dec-6eb8-47d6-b7f8-52db6ea4b88a",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 855
   },
   "source": "# Agent (=> GNN+FNN) \n# N => number nodes\n# D => number dimensions\n# stack_channels => integer or list of integers, number of channels for the hidden layers\n# node_channels => integer, number of output channels for the nodes\n# edge_channels => integer, number of output channels for the edges\n# division_factor_dense => integer, gradually reduce the number of neurons for each dense layer\n# p_drop => float between 0 and 1, fraction of the input units to drop\n# N_xenet => Number of XENetDenseConv layers\n# N_dense => Number of Dense hidden layers\n\ndef agent(N,                                 \n          D,                                 \n          stack_channels=5,        \n          node_channels=3,\n          edge_channels=3,\n          division_factor_dense=4,\n          p_drop=0,\n          N_xenet=2,\n          N_dense=2,\n          activation=\"relu\",\n          regularizer=0):\n  inX = Input(shape=(N,1), name='Input Nodes')\n  inA = Input(shape=(N,N), name='Input Adj matrix')\n  inE = Input(shape=(N,N,1), name='Input Edges')\n  \n  XENet_layer = XENetDenseConv(stack_channels, node_channels, edge_channels,\n                     attention=True, node_activation=activation, edge_activation=activation, kernel_regularizer=l2(regularizer), name=\"XENet_layer\")\n  X, E = XENet_layer([inX, inA, inE])\n  for i in range(N_xenet-1):\n    X, E = XENet_layer([X, inA, E])\n  \n  # flat the updated X, E in order to feed the fully connected neural network (FNN)\n  flat_x, flat_e = Flatten(name=\"Nodes_encoding\")(X), Flatten(name=\"Edges_encoding\")(E)\n  out = Concatenate(axis=1, name=\"Concatenation\")([flat_x])    #,flat_e\n  \n  for i in range(N_dense):\n    out = Dense(out.shape.as_list()[1]//division_factor_dense, activation=activation, kernel_regularizer=l2(regularizer))(out)\n    out = Dropout(p_drop)(out)\n  out = Dense(N, activation=activation, kernel_regularizer=l2(regularizer), name='Q-values')(out)\n  \n  model = Model([inX,inA,inE], out)\n  model.compile(optimizer=Adam(), loss=MeanSquaredError())\n  return model",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Training",
   "metadata": {
    "tags": [],
    "cell_id": "00015-9878744a-0863-40b1-8a95-6bf41ae963a3",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a735eeeb",
    "execution_start": 1653930475548,
    "execution_millis": 0,
    "cell_id": "00016-61bb69a7-f518-4aef-9e45-824f2a8b696e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 981
   },
   "source": "def train(env, replay_memory, model, target_model, done):\n    discount_factor = 0.618\n    \n    # skip the training if the number of samples in the replay \n    # memory is less than MIN_REPLAY_SIZE\n    MIN_REPLAY_SIZE = 32\n    if len(replay_memory) < MIN_REPLAY_SIZE:\n        return\n\n    # randomly select a number of samples from the replay memory equal to batch_size\n    batch_size = 32\n    mini_batch = random.sample(replay_memory, batch_size)\n\n    # sets of all interaction matrix and dense adjacency matrix in the batch\n    E = np.array([transition[-1] for transition in mini_batch])\n    A = np.array([transition[-2] for transition in mini_batch])\n\n    # current_states => set of all starting observations in the batch\n    # current_qs_list => predicted Q-values of the current_states by the model\n    current_states = np.array([transition[0] for transition in mini_batch])\n    current_qs_list = np.array(model.predict([current_states,A,E]))\n \n    # new_current_states => set of observations after performing n actions in the batch\n    # future_qs_list => predicted Q-values of the new_current_states by the target model\n    new_current_states = np.array([transition[3] for transition in mini_batch])\n    future_qs_list = np.array(target_model.predict([new_current_states,A,E]))\n    \n    # X => observations\n    # Y => 'label' of each observation: updated current_qs_list \n    X = []\n    Y = []\n    for index, (observation, action, reward, new_observation, done, dense_AdjMat, inter_matrix) in enumerate(mini_batch):\n        if not done:\n            new_q = reward + discount_factor*np.max(future_qs_list[index])\n        else:\n            new_q = reward\n\n        # update the Q-value corrisponding to the performed action\n        current_qs = current_qs_list[index]\n        current_qs[action] = new_q\n        \n        X.append(observation)\n        Y.append(current_qs)\n\n    # build the training dataset \n    train_data = MyDataset(N_graph=batch_size, X=X, Y=Y, A=A, E=E)\n    # use the BatchLoader to fit the model and WandbCallback to load the loss to Weight&Biases\n    loader = BatchLoader(train_data, node_level=False, epochs=50, batch_size=batch_size, shuffle=False) \n    model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, verbose=2,\n                callbacks = [WandbCallback()])\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b0e58ee7",
    "execution_start": 1653930475560,
    "execution_millis": 21,
    "cell_id": "00017-1683d0c1-2d32-47ff-ad06-468a3e699861",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1809
   },
   "source": "def main():\n    L = 3\n    D = 2\n    env = SG_env(L=L, D=D)\n\n    # Epsilon-greedy algorithm in initialized at 1 \n    # => every step is random at the start\n    epsilon = 1          \n    max_epsilon = 1     \n    min_epsilon = 0.01  \n    decay = 0.01\n\n    # 1. Initialize the Target and Main models \n    # Main Model (updated every 3 steps)\n    model = agent(N=env.N, D=D, N_xenet=1, N_dense=0, division_factor_dense=2)\n\n    # Target Model (updated at the end of every episode)\n    target_model = agent(N=env.N, D=D, N_xenet=1, N_dense=0, division_factor_dense=2)\n    target_model.set_weights(model.get_weights())\n\n    energy_buffer = []\n    replay_memory = []\n    \n    train_episodes = 300\n    for episode in range(train_episodes):\n        # reset the variables at the beginning of an episode\n        trajectory_buffer = []                   \n        steps_to_update_target_model = 0\n        env.reset()\n        previous_obs = np.ones(shape=(env.N,1)).astype(\"int32\")\n        done = False  \n        check = np.arange(0,env.N)\n\n        while not done: \n            observation = env.get_state()          \n            print(\"\\n\\t\\t\\t\\t++++++++++++  episode:\", episode,\" - step:\", steps_to_update_target_model, \" ++++++++++++\")\n\n            # 2. Explore using the Epsilon Greedy Exploration Strategy\n            random_number = np.random.rand()\n            if random_number <= epsilon:\n                # Explore\n                action = random.choice(check)\n\n            else:\n                # Exploit best known action\n                predicted = model([observation.reshape(1,env.N,1), env.dense_AdjMat.reshape(1,env.N,env.N), env.inter_matrix.reshape(1,env.N,env.N,1)], training=False).numpy()[0]\n                while True:\n                    # check to prevent flipping the same spin twice - only once!\n                    action = np.argmax(predicted)\n                    if env.get_state()[action,0] == 1:\n                            break;\n                    predicted[action] = np.NINF\n\n            # remove the choosen action from check array\n            check = np.setdiff1d(check, action)\n\n            # perform the action on the environment and get the updated parameters\n            step_type, reward, discount, new_observation = env._step(action)\n            done = env._episode_ended\n            e = env.computeEnergy()\n\n            # save the parameter in the buffer\n            trajectory_buffer.append([previous_obs, action, reward, new_observation, done, e, env.dense_AdjMat, env.inter_matrix])\n            energy_buffer.append([episode, new_observation, env.interaction, e])  \n            \n            # load interesting parameters to weight&Biases\n            wandb.log({\n                \"Episode\": energy_buffer[episode*env.N+steps_to_update_target_model][0],\n                \"Step\": episode*env.N+steps_to_update_target_model,\n                \"New observation\": energy_buffer[episode*env.N+steps_to_update_target_model][1],\n                \"J interactions\": energy_buffer[episode*env.N+steps_to_update_target_model][2],\n                \"Energy\": energy_buffer[episode*env.N+steps_to_update_target_model][3]\n            })\n\n            # fill the replay memory buffer\n            if steps_to_update_target_model >= L:   \n                replay_memory = get_replay_memory(trajectory_buffer, replay_memory)\n                trajectory_buffer = trajectory_buffer[1:]\n\n            # 3. Update the Main Network using the Bellman Equation  \n            if (steps_to_update_target_model%L==0 and steps_to_update_target_model!=0) or done:\n                print(\"\\n\\t\\t\\t\\t\\t      +++++ Training +++++\")\n                train(env, replay_memory, model, target_model, done)\n  \n            previous_obs = new_observation\n\n            # Copying main network weights to the target network\n            # weights at the end of the episode\n            if done:\n                if episode >= 5:\n                    target_model.set_weights(model.get_weights())\n                break\n\n            steps_to_update_target_model += 1\n\n        # update epsilon using the following rule\n        epsilon = min_epsilon+ (max_epsilon -min_epsilon) * np.exp(-decay *episode)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "286a4539",
    "execution_start": 1653930475625,
    "execution_millis": 395430,
    "cell_id": "00018-fa31b9e1-5abd-45dc-87e2-3c43851c8d6d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 701
   },
   "source": "main()",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\t\t\t\t++++++++++++  episode: 277  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.9174 - _timestamp: 1653930841.0000 - _runtime: 369.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 277  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.8080 - _timestamp: 1653930841.0000 - _runtime: 369.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2597 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 16ms/epoch - 16ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.7336 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 16ms/epoch - 16ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2445 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7818 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.0943 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5690 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.5418 - _timestamp: 1653930842.0000 - _runtime: 370.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.5566 - _timestamp: 1653930843.0000 - _runtime: 371.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 278  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.5478 - _timestamp: 1653930843.0000 - _runtime: 371.0000 - 13ms/epoch - 13ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.9659 - _timestamp: 1653930843.0000 - _runtime: 371.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0972 - _timestamp: 1653930843.0000 - _runtime: 371.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.5915 - _timestamp: 1653930843.0000 - _runtime: 371.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2056 - _timestamp: 1653930843.0000 - _runtime: 371.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.3061 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.7921 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0540 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.3149 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 279  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7561 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 7.6433 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7193 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1171 - _timestamp: 1653930844.0000 - _runtime: 372.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4916 - _timestamp: 1653930845.0000 - _runtime: 373.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 6.7425 - _timestamp: 1653930845.0000 - _runtime: 373.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0493 - _timestamp: 1653930845.0000 - _runtime: 373.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.5696 - _timestamp: 1653930845.0000 - _runtime: 373.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.5897 - _timestamp: 1653930845.0000 - _runtime: 373.0000 - 14ms/epoch - 14ms/step\n\n\t\t\t\t++++++++++++  episode: 280  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.5462 - _timestamp: 1653930845.0000 - _runtime: 373.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7552 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1117 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 14ms/epoch - 14ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 6.4609 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.3340 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.9025 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0751 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2559 - _timestamp: 1653930846.0000 - _runtime: 374.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2337 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 281  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.9841 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7371 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0715 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.4459 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.9720 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8526 - _timestamp: 1653930847.0000 - _runtime: 375.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.3656 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1350 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7397 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 282  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6969 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5758 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.8044 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.2683 - _timestamp: 1653930848.0000 - _runtime: 376.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0542 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1612 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4965 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.4118 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.5600 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 283  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0736 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5173 - _timestamp: 1653930849.0000 - _runtime: 377.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8442 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.8951 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0647 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.4412 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.0869 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.8393 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.4757 - _timestamp: 1653930850.0000 - _runtime: 378.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 284  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0056 - _timestamp: 1653930851.0000 - _runtime: 379.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1501 - _timestamp: 1653930851.0000 - _runtime: 379.0000 - 14ms/epoch - 14ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.3663 - _timestamp: 1653930851.0000 - _runtime: 379.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.3921 - _timestamp: 1653930851.0000 - _runtime: 379.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.7487 - _timestamp: 1653930851.0000 - _runtime: 379.0000 - 15ms/epoch - 15ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8567 - _timestamp: 1653930851.0000 - _runtime: 379.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0797 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.5561 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.1608 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 285  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4431 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.4110 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.5671 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.9397 - _timestamp: 1653930852.0000 - _runtime: 380.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5861 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7271 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.3442 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6637 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0908 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 286  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8495 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0462 - _timestamp: 1653930853.0000 - _runtime: 381.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7592 - _timestamp: 1653930854.0000 - _runtime: 382.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2181 - _timestamp: 1653930854.0000 - _runtime: 382.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.1902 - _timestamp: 1653930854.0000 - _runtime: 382.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.3264 - _timestamp: 1653930854.0000 - _runtime: 382.0000 - 15ms/epoch - 15ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0745 - _timestamp: 1653930854.0000 - _runtime: 382.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7439 - _timestamp: 1653930854.0000 - _runtime: 382.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.8076 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 287  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.6506 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1830 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 13ms/epoch - 13ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5390 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.9046 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4785 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.5754 - _timestamp: 1653930855.0000 - _runtime: 383.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.3345 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1386 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.7919 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 288  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 6.4302 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.6694 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 15ms/epoch - 15ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.3076 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 13ms/epoch - 13ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.7939 - _timestamp: 1653930856.0000 - _runtime: 384.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.2335 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.6284 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5859 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1707 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.5843 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 289  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7254 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4834 - _timestamp: 1653930857.0000 - _runtime: 385.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.3682 - _timestamp: 1653930858.0000 - _runtime: 386.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.6288 - _timestamp: 1653930858.0000 - _runtime: 386.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.9759 - _timestamp: 1653930858.0000 - _runtime: 386.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.4319 - _timestamp: 1653930858.0000 - _runtime: 386.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.6941 - _timestamp: 1653930858.0000 - _runtime: 386.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.7303 - _timestamp: 1653930858.0000 - _runtime: 386.0000 - 14ms/epoch - 14ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.4977 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 290  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.9880 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7495 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.3297 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.8433 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 10.5647 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6128 - _timestamp: 1653930859.0000 - _runtime: 387.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2560 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0060 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0073 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 291  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.5786 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.1718 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1278 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7852 - _timestamp: 1653930860.0000 - _runtime: 388.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4676 - _timestamp: 1653930861.0000 - _runtime: 389.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1874 - _timestamp: 1653930861.0000 - _runtime: 389.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.3320 - _timestamp: 1653930861.0000 - _runtime: 389.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.8895 - _timestamp: 1653930861.0000 - _runtime: 389.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.9863 - _timestamp: 1653930861.0000 - _runtime: 389.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 292  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1824 - _timestamp: 1653930861.0000 - _runtime: 389.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.6929 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.1319 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.9650 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4035 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1174 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7117 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7610 - _timestamp: 1653930862.0000 - _runtime: 390.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.6761 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 15ms/epoch - 15ms/step\n\n\t\t\t\t++++++++++++  episode: 293  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.8469 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 31ms/epoch - 31ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.3561 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 13ms/epoch - 13ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6077 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 14ms/epoch - 14ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 5.6032 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8425 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2124 - _timestamp: 1653930863.0000 - _runtime: 391.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.1951 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.9597 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4349 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 294  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7476 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.5100 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.4884 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4026 - _timestamp: 1653930864.0000 - _runtime: 392.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 6.4168 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.6333 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1358 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4249 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0509 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 295  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.3185 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.5207 - _timestamp: 1653930865.0000 - _runtime: 393.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.7472 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8936 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 17ms/epoch - 17ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.3163 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1509 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0823 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.2776 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1597 - _timestamp: 1653930866.0000 - _runtime: 394.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 296  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.1677 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.7536 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.8892 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.8014 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2595 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.6377 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.1199 - _timestamp: 1653930867.0000 - _runtime: 395.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.5877 - _timestamp: 1653930868.0000 - _runtime: 396.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0662 - _timestamp: 1653930868.0000 - _runtime: 396.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 297  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6786 - _timestamp: 1653930868.0000 - _runtime: 396.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0194 - _timestamp: 1653930868.0000 - _runtime: 396.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.7809 - _timestamp: 1653930868.0000 - _runtime: 396.0000 - 12ms/epoch - 12ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.8390 - _timestamp: 1653930868.0000 - _runtime: 396.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6822 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.0569 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.4727 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.6003 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2688 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 298  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.0439 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.2142 - _timestamp: 1653930869.0000 - _runtime: 397.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.0768 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.4131 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 1.3555 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.7709 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 10ms/epoch - 10ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 4.9498 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.4365 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 3.2698 - _timestamp: 1653930870.0000 - _runtime: 398.0000 - 11ms/epoch - 11ms/step\n\n\t\t\t\t++++++++++++  episode: 299  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n1/1 - 0s - loss: 2.8767 - _timestamp: 1653930871.0000 - _runtime: 399.0000 - 11ms/epoch - 11ms/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1ef4273f",
    "execution_start": 1653930871096,
    "execution_millis": 3711,
    "cell_id": "00019-a26194ed-603c-4880-b073-09461f53216b",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 757.5,
    "deepnote_output_heights": [
     21.1875,
     483.75,
     40.375,
     22.1875
    ]
   },
   "source": "wandb.finish()",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Energy</td><td></td></tr><tr><td>Episode</td><td></td></tr><tr><td>Step</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Energy</td><td>6.68031</td></tr><tr><td>Episode</td><td>299</td></tr><tr><td>Step</td><td>2699</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.87667</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">golden-star-13</strong>: <a href=\"https://wandb.ai/locp/test-project/runs/1blglopm\" target=\"_blank\">https://wandb.ai/locp/test-project/runs/1blglopm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20220530_170752-1blglopm/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9515997f-d5de-4c93-8ae3-fa9b47581edf' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "952b67d7-1b25-4702-8bea-d6f8bf4ce408",
  "deepnote_execution_queue": []
 }
}